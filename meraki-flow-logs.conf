######################################################################################
#                                                                                  
#  Meraki Flow Logs (from Syslog, not netflow) Confgiguration                                                  
#                                                                                  
#  Last Revised:   01/03/2019 
#  Transport:      udp 9514                                   
#  Compatibility:  ecs 1.5.0 dev                                    
#  Notes:   gsub fix for meraki .s in names
#           updated to arrays for nested fields, added domain fixes  
#           These logs are more akin to NSEL, showing connections and
#           firewall actions
######################################################################################

## discrete port for easy identification
input {
      udp {
      
        ## I've run into *nix configs that default to ipv6 and won't open an
        ## IPv4 port w/o hard coding, have yet to figure out why, so often hard 
        ## code IP the pipeline should listen on
        
        host => [logstash ip address]
        
        ## Update port for your environment, easiest way is to split Meraki
        ## Logs - URLs, events, etc to different ports. Configs coming
        ## soon for a single Meraki syslog target & multiple pipelines
        
        port  => 9515
    }
}

filter {

    ######################################################
    ###        Optional: Hash Original Message         ###
    ######################################################
    fingerprint {
        target => "[event][hash]"
    }

    grok {    
        match => { "message" => "%{INT:[millis]}.%{INT:[nanos]} %{WORD:[observer][name]} %{WORD:[event][module]} ?(?:%{WORD:[event][action]})? src=%{IP:[source][ip]} dst=%{IP:[destination][ip]} mac=%{MAC:[source][mac]} protocol=%{WORD:[network][protocol]} sport=%{NUMBER:[source][port]} dport=%{NUMBER:[destination][port]} ?(?:pattern: %{GREEDYDATA:[event][action]})?"}
        match => { "message" => "%{INT:[millis]}.%{INT:[nanos]} ip_flow_%{NOTSPACE:flow_state} src=%{IP:[source][ip]} dst=%{IP:[destination][ip]} protocol=%{WORD:[network][transport]} sport=%{NUMBER:[source][port]} dport=%{NUMBER:[destination][port]} translated_src_ip=%{IP:[source][nat][ip]} translated_port=%{NUMBER:[source][nat][port]}" }
    }   

    truncate {
            fields => "nanos"
            length_bytes => 3
    }

     mutate {

        ######################################################
        ###                Add core ECS fields             ###
        ######################################################
        add_field => { "[event][kind]" => "event" }
        add_field => { "[event][category]" => "network"}
        add_field => { "[event][type]" => "connection_%{flow_state}"}
        add_field => { "[event][dataset]" => "meraki.flow-logs" }
        add_field => { "[event][outcome]" => "success"}
        add_field => { "[ecs][version]" => "1.5.0" }
        add_field => { "[event][original]" => "%{message}" }

        ######################################################
        ###          Use event time for @timestamp         ###
        ######################################################
        add_field => { "[event][created]" => "%{@timestamp}" }
        ##update => { "@timestamp" =>"%{millis}%{nanos}" }

        ######################################################
        ###             Populate Observer fields           ###
        ######################################################
        add_field => { "[observer][vendor]" => "meraki" }
        rename =>    { "[host]" => "[observer][ip]"  }

        gsub => [ "[observer][name]", "_", "." ]

        #remove temp fields, etc.
        remove_field => [ "millis", "nanos", "flow_state" ]

    }
}

output {
    elasticsearch {
        hosts => "${ES_URL}"
        user => "${ES_INGEST}"
        password => "${ES_INGEST_PW}"
        index => "ecs-meraki-flows"
        pipeline => "meraki-flow-log"
    }
}
